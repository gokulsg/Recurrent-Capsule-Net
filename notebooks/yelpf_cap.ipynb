{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fx1_y19h9U5W"
   },
   "source": [
    "# Recurrent Capsule Network for Yelp Reviews Dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y_6nJR309gkK"
   },
   "source": [
    "## Kaggle API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 454
    },
    "colab_type": "code",
    "id": "yW5P1lkyTw46",
    "outputId": "31ce65d6-3382-4361-922c-a4aa72f41172"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kaggle\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c6/78/832b9a9ec6b3baf8ec566e1f0a695f2fd08d2c94a6797257a106304bfc3c/kaggle-1.4.7.1.tar.gz (52kB)\n",
      "\r",
      "\u001b[K    19% |██████▎                         | 10kB 17.6MB/s eta 0:00:01\r",
      "\u001b[K    38% |████████████▌                   | 20kB 1.8MB/s eta 0:00:01\r",
      "\u001b[K    58% |██████████████████▊             | 30kB 2.6MB/s eta 0:00:01\r",
      "\u001b[K    77% |█████████████████████████       | 40kB 1.7MB/s eta 0:00:01\r",
      "\u001b[K    97% |███████████████████████████████▏| 51kB 2.2MB/s eta 0:00:01\r",
      "\u001b[K    100% |████████████████████████████████| 61kB 2.4MB/s \n",
      "\u001b[?25hRequirement already satisfied: urllib3<1.23.0,>=1.15 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.22)\n",
      "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.11.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2018.10.15)\n",
      "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.5.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.18.4)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.27.0)\n",
      "Collecting python-slugify (from kaggle)\n",
      "  Downloading https://files.pythonhosted.org/packages/00/ad/c778a6df614b6217c30fe80045b365bfa08b5dd3cb02e8b37a6d25126781/python-slugify-1.2.6.tar.gz\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.6)\n",
      "Collecting Unidecode>=0.04.16 (from python-slugify->kaggle)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/59/ef/67085e30e8bbcdd76e2f0a4ad8151c13a2c5bce77c85f8cad6e1f16fb141/Unidecode-1.0.22-py2.py3-none-any.whl (235kB)\n",
      "\u001b[K    100% |████████████████████████████████| 235kB 7.4MB/s \n",
      "\u001b[?25hBuilding wheels for collected packages: kaggle, python-slugify\n",
      "  Running setup.py bdist_wheel for kaggle ... \u001b[?25l-\b \b\\\b \bdone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/44/2c/df/22a6eeb780c36c28190faef6252b739fdc47145fd87a6642d4\n",
      "  Running setup.py bdist_wheel for python-slugify ... \u001b[?25l-\b \bdone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/e3/65/da/2045deea3098ed7471eca0e2460cfbd3fdfe8c1d6fa6fcac92\n",
      "Successfully built kaggle python-slugify\n",
      "Installing collected packages: Unidecode, python-slugify, kaggle\n",
      "Successfully installed Unidecode-1.0.22 kaggle-1.4.7.1 python-slugify-1.2.6\n"
     ]
    }
   ],
   "source": [
    "!pip install kaggle\n",
    "!mkdir -p ~/.kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ndHLm1_4WnZf"
   },
   "outputs": [],
   "source": [
    "api_token = {\"username\":\"rsrade\", \"key\":\"91ef4b76e3b11ee6844771852817941e\"}\n",
    "\n",
    "import json\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "with open('/content/kaggle.json', 'w') as file:\n",
    "    json.dump(api_token, file)\n",
    "    \n",
    "!mv /content/kaggle.json ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "id": "-5rRxuvqWsay",
    "outputId": "64a095a6-dc42-4b56-8801-d60290239295"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- path is now set to: /content\n",
      "Downloading yelp_academic_dataset_review.json.zip to /content/datasets/yelp-dataset/yelp-dataset\n",
      "100% 1.69G/1.70G [00:49<00:00, 40.1MB/s]\n",
      "100% 1.70G/1.70G [00:49<00:00, 37.0MB/s]\n"
     ]
    }
   ],
   "source": [
    "!chmod 600 ~/.kaggle/kaggle.json\n",
    "!kaggle config set -n path -v /content\n",
    "!kaggle datasets download yelp-dataset/yelp-dataset -f yelp_academic_dataset_review.json\n",
    "# os.chdir('/content/')\n",
    "# for file in os.listdir():\n",
    "#     zip_ref = zipfile.ZipFile(file, 'r')\n",
    "#     zip_ref.extractall()\n",
    "#     zip_ref.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L_OfwtVU9lEw"
   },
   "source": [
    "## Load Train and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tq-81Iw29KTj"
   },
   "outputs": [],
   "source": [
    "os.chdir('/content/')\n",
    "zip_ref = zipfile.ZipFile('/content/datasets/yelp-dataset/yelp-dataset/yelp_academic_dataset_review.json.zip', 'r')\n",
    "zip_ref.extractall()\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "TRcKCEW9T9po",
    "outputId": "3e59d783-a00b-4e2a-efe3-8e8bd3cbd82e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.config', 'sample_data', 'datasets', 'yelp_academic_dataset_review.json']"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.listdir('/content/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k09qD2Db9qd1"
   },
   "outputs": [],
   "source": [
    "!rm -r datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uH2lHYmnwRrg"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "fh = open('/content/yelp_academic_dataset_review.json')\n",
    "#initialize \n",
    "df = []\n",
    " \n",
    "#each line in file is a json string\n",
    "for line in fh:\n",
    "    #load json to dict\n",
    "    tip = json.loads(line)\n",
    "    df.append(tip)\n",
    "    if (len(df))>650000:\n",
    "        break\n",
    "fh.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "JUkwuWYRwl_b",
    "outputId": "91b79f1f-26ec-4f99-a308-f4108b24cef4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101, 9)"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train_df = pd.DataFrame(df)\n",
    "del df\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191
    },
    "colab_type": "code",
    "id": "D0EBL14OU8fe",
    "outputId": "e4f83e83-d034-4276-d96b-f8d78dbc9666"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "business_id                               yFumR3CWzpfvTH2FCthvVw\n",
       "cool                                                           0\n",
       "date                                                  2016-06-15\n",
       "funny                                                          0\n",
       "review_id                                 STiFMww2z31siPY7BWNC2g\n",
       "stars                                                          5\n",
       "text           I have been an Emerald Club member for a numbe...\n",
       "useful                                                         0\n",
       "user_id                                   TlvV-xJhmh7LCwJYXkV-cg\n",
       "Name: 10, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.iloc[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "nD1fOYv0a6rf",
    "outputId": "e5cd02ee-14fa-40a6-aca1-dcc3aaea9a24"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((40000, 9), (610000, 9))"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = train_df[610001:]\n",
    "train_df = train_df[:610000]\n",
    "test_df.shape, train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Oroz4pwtBhvr",
    "outputId": "1918cb22-d73c-4982-d781-8f7c57d34415"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((40000, 9), (610000, 9))"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape, train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "i4mL7Jj-V2XQ",
    "outputId": "213f58f1-2570-414c-a719-5c007930774c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing, model_selection, metrics\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import os\n",
    "from keras.layers import Dense,Input,LSTM,Bidirectional,Activation,Conv1D,GRU\n",
    "from keras.callbacks import Callback\n",
    "from keras.layers import Dropout,Embedding,GlobalMaxPooling1D, MaxPooling1D, Add, Flatten\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras.layers import GlobalAveragePooling1D, GlobalMaxPooling1D, concatenate, SpatialDropout1D\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers, callbacks\n",
    "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ndv6dNmhaXQx"
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "from keras import initializers, regularizers, constraints\n",
    "\n",
    "EMBEDDING_FILE='/content/datalab/glove.840B.300d.txt'\n",
    "\n",
    "MAX_SEQUENCE_LENGTH = 150\n",
    "MAX_NB_WORDS = 100000\n",
    "EMBEDDING_DIM = 300\n",
    "VALIDATION_SPLIT = 0.1\n",
    "\n",
    "num_lstm = 300\n",
    "num_dense = 256\n",
    "rate_drop_lstm = 0.2\n",
    "rate_drop_dense = 0.2\n",
    "\n",
    "act = 'relu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-_xcthRwaY9A"
   },
   "outputs": [],
   "source": [
    "def cleanData(text, stemming = False, lemmatize=False):    \n",
    "    text = text.lower().split()\n",
    "    text = \" \".join(text)\n",
    "    text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+\\-=]\", \" \", text)\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"can't\", \"cannot \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\",\", \" \", text)\n",
    "    text = re.sub(r\"\\.\", \" \", text)\n",
    "    text = re.sub(r\"!\", \" ! \", text)\n",
    "    text = re.sub(r\"\\/\", \" \", text)\n",
    "    text = re.sub(r\"\\^\", \" ^ \", text)\n",
    "    text = re.sub(r\"\\+\", \" + \", text)\n",
    "    text = re.sub(r\"\\-\", \" - \", text)\n",
    "    text = re.sub(r\"\\=\", \" = \", text)\n",
    "    text = re.sub(r\"'\", \" \", text)\n",
    "    text = re.sub(r\"(\\d+)(k)\", r\"\\g<1>000\", text)\n",
    "    text = re.sub(r\":\", \" : \", text)\n",
    "    text = re.sub(r\" e g \", \" eg \", text)\n",
    "    text = re.sub(r\" b g \", \" bg \", text)\n",
    "    text = re.sub(r\" u s \", \" american \", text)\n",
    "    text = re.sub(r\"\\0s\", \"0\", text)\n",
    "    text = re.sub(r\" 9 11 \", \"911\", text)\n",
    "    text = re.sub(r\"e - mail\", \"email\", text)\n",
    "    text = re.sub(r\"j k\", \"jk\", text)\n",
    "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
    "    if stemming:\n",
    "        st = PorterStemmer()\n",
    "        txt = \" \".join([st.stem(w) for w in text.split()])\n",
    "    if lemmatize:\n",
    "        wordnet_lemmatizer = WordNetLemmatizer()\n",
    "        txt = \" \".join([wordnet_lemmatizer.lemmatize(w) for w in text.split()])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YWtATJd49wsv"
   },
   "source": [
    "## Download Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "id": "PZBx2oWxaZB1",
    "outputId": "1a0c979a-bb87-4b7f-afdf-f4352f0b4929"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2018-09-06 13:19:07--  http://nlp.stanford.edu/data/glove.840B.300d.zip\n",
      "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://nlp.stanford.edu/data/glove.840B.300d.zip [following]\n",
      "--2018-09-06 13:19:08--  https://nlp.stanford.edu/data/glove.840B.300d.zip\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2176768927 (2.0G) [application/zip]\n",
      "Saving to: ‘glove.840B.300d.zip’\n",
      "\n",
      "glove.840B.300d.zip 100%[===================>]   2.03G  10.1MB/s    in 3m 17s  \n",
      "\n",
      "2018-09-06 13:22:25 (10.5 MB/s) - ‘glove.840B.300d.zip’ saved [2176768927/2176768927]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://nlp.stanford.edu/data/glove.840B.300d.zip\n",
    "\n",
    "import zipfile\n",
    "zip_ref = zipfile.ZipFile('glove.840B.300d.zip', 'r')\n",
    "zip_ref.extractall('/content/datalab/')\n",
    "zip_ref.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DR_fY_KC90Su"
   },
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AI6rGbaBaZVn"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import csv\n",
    "import codecs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from string import punctuation\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import *\n",
    "from keras.layers import concatenate, CuDNNGRU\n",
    "from keras.models import Model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "kFWGdhnbCFEP",
    "outputId": "b9dd9b46-bd9e-4f62-ce04-1e6efaf1d546"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['business_id', 'cool', 'date', 'funny', 'review_id', 'stars', 'text',\n",
       "       'useful', 'user_id'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "X1TNGJyUCIGr",
    "outputId": "075b7ea3-3b30-4da8-aee5-ba9a1888f3ff"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(610000, 2)"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.drop(['business_id', 'cool', 'date', 'funny', 'review_id', 'useful', 'user_id'], axis=1, inplace=True)\n",
    "test_df.drop(['business_id', 'cool', 'date', 'funny', 'review_id', 'useful', 'user_id'], axis=1, inplace=True)\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "W77_OvYZdqEH",
    "outputId": "49fb2891-c869-416e-b13d-31b62fa06801"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>The pizza was okay. Not the best I've had. I p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>I love this place! My fiance And I go here atl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Terrible. Dry corn bread. Rib tips were all fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Back in 2005-2007 this place was my FAVORITE t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Delicious healthy food. The steak is amazing. ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stars                                               text\n",
       "0      2  The pizza was okay. Not the best I've had. I p...\n",
       "1      5  I love this place! My fiance And I go here atl...\n",
       "2      1  Terrible. Dry corn bread. Rib tips were all fa...\n",
       "3      2  Back in 2005-2007 this place was my FAVORITE t...\n",
       "4      5  Delicious healthy food. The steak is amazing. ..."
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vNFHipo5hBcD"
   },
   "outputs": [],
   "source": [
    "train_df['stars'].astype('object', inplace=True)\n",
    "train_df = pd.concat([train_df, pd.get_dummies(train_df['stars'], prefix='star')], axis=1)\n",
    "\n",
    "# now drop the original 'country' column (you don't need it anymore)\n",
    "# train_df.drop(['stars'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QQx_s_IOhR94"
   },
   "outputs": [],
   "source": [
    "test_df['stars'].astype('object', inplace=True)\n",
    "test_df = pd.concat([test_df, pd.get_dummies(test_df['stars'], prefix='star')], axis=1)\n",
    "\n",
    "# now drop the original 'country' column (you don't need it anymore)\n",
    "# test_df.drop(['stars'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "0BLOSrN0h9mR",
    "outputId": "cbe69ac8-ec71-4101-a909-5018359fc49a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>star_1</th>\n",
       "      <th>star_2</th>\n",
       "      <th>star_3</th>\n",
       "      <th>star_4</th>\n",
       "      <th>star_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>The pizza was okay. Not the best I've had. I p...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>I love this place! My fiance And I go here atl...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Terrible. Dry corn bread. Rib tips were all fa...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Back in 2005-2007 this place was my FAVORITE t...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Delicious healthy food. The steak is amazing. ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stars                                               text  star_1  star_2  \\\n",
       "0      2  The pizza was okay. Not the best I've had. I p...       0       1   \n",
       "1      5  I love this place! My fiance And I go here atl...       0       0   \n",
       "2      1  Terrible. Dry corn bread. Rib tips were all fa...       1       0   \n",
       "3      2  Back in 2005-2007 this place was my FAVORITE t...       0       1   \n",
       "4      5  Delicious healthy food. The steak is amazing. ...       0       0   \n",
       "\n",
       "   star_3  star_4  star_5  \n",
       "0       0       0       0  \n",
       "1       0       0       1  \n",
       "2       0       0       0  \n",
       "3       0       0       0  \n",
       "4       0       0       1  "
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "FevMffBYaZAS",
    "outputId": "e4435c6d-8f62-4e55-812f-3732aa0d00bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing text dataset\n",
      "Found 196975 unique tokens\n",
      "Shape of data tensor: (610000, 150)\n",
      "Shape of label tensor: (610000, 5)\n",
      "Shape of test_data tensor: (40000, 150)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "col_text = 'text'\n",
    "list_classes = [\"star_1\", \"star_2\", \"star_3\", \"star_4\", \"star_5\"]\n",
    "\n",
    "print('Processing text dataset')\n",
    "\n",
    "train_df[col_text] = train_df[col_text].map(lambda x: cleanData(x, stemming=False, lemmatize=False))\n",
    "test_df[col_text] = test_df[col_text].map(lambda x: cleanData(x, stemming=False, lemmatize=False))\n",
    "\n",
    "#Regex to remove all Non-Alpha Numeric and space\n",
    "special_character_removal=re.compile(r'[^a-z\\d ]',re.IGNORECASE)\n",
    "#regex to replace all numerics\n",
    "replace_numbers=re.compile(r'\\d+',re.IGNORECASE)\n",
    "\n",
    "def text_to_wordlist(text, remove_stopwords=False, stem_words=False):\n",
    "    text = text.lower().split()\n",
    "\n",
    "    # Optionally, remove stop words\n",
    "    if remove_stopwords:\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        text = [w for w in text if not w in stops]\n",
    "    \n",
    "    text = \" \".join(text)\n",
    "    \n",
    "    #Remove Special Characters\n",
    "    text=special_character_removal.sub('',text)\n",
    "    #Replace Numbers\n",
    "    text=replace_numbers.sub('n',text)\n",
    "\n",
    "    # Optionally, shorten words to their stems\n",
    "    if stem_words:\n",
    "        text = text.split()\n",
    "        stemmer = SnowballStemmer('english')\n",
    "        stemmed_words = [stemmer.stem(word) for word in text]\n",
    "        text = \" \".join(stemmed_words)\n",
    "    \n",
    "    return(text)\n",
    "\n",
    "\n",
    "list_sentences_train = train_df[col_text].fillna(\"NA\").values\n",
    "y = train_df[list_classes].values\n",
    "list_sentences_test = test_df[col_text].fillna(\"NA\").values\n",
    "\n",
    "\n",
    "comments = []\n",
    "for text in list_sentences_train:\n",
    "    comments.append(text_to_wordlist(text))\n",
    "    \n",
    "test_comments=[]\n",
    "for text in list_sentences_test:\n",
    "    test_comments.append(text_to_wordlist(text))\n",
    "\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
    "tokenizer.fit_on_texts(comments + test_comments)\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(comments)\n",
    "test_sequences = tokenizer.texts_to_sequences(test_comments)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens' % len(word_index))\n",
    "\n",
    "data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "print('Shape of data tensor:', data.shape)\n",
    "print('Shape of label tensor:', y.shape)\n",
    "\n",
    "test_data = pad_sequences(test_sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "print('Shape of test_data tensor:', test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "nMzwCzp-d180",
    "outputId": "65356b93-71ee-4379-d991-5711c2ac5ef7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (610000, 150)\n",
      "Shape of label tensor: (610000, 5)\n",
      "Shape of test_data tensor: (40000, 150)\n"
     ]
    }
   ],
   "source": [
    "data_post = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH,padding='post', truncating='post')\n",
    "print('Shape of data tensor:', data_post.shape)\n",
    "print('Shape of label tensor:', y.shape)\n",
    "\n",
    "test_data_post = pad_sequences(test_sequences, maxlen=MAX_SEQUENCE_LENGTH, padding='post', truncating='post')\n",
    "print('Shape of test_data tensor:', test_data_post.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QjrPYIfeywBR"
   },
   "outputs": [],
   "source": [
    "del train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "oaHi4Seqd2ra",
    "outputId": "5a55dd13-1b2d-4cf1-f5d2-13abb5794392"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing word vectors\n",
      "Found 2195895 word vectors of glove.\n",
      "-0.01444638 0.47249147\n",
      "Total 2195895 word vectors.\n"
     ]
    }
   ],
   "source": [
    "print('Indexing word vectors')\n",
    "\n",
    "count = 0\n",
    "embeddings_index = {}\n",
    "f = open(EMBEDDING_FILE)\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = ' '.join(values[:-300])\n",
    "    coefs = np.asarray(values[-300:], dtype='float32')\n",
    "    embeddings_index[word] = coefs.reshape(-1)\n",
    "    coef = embeddings_index[word]\n",
    "f.close()\n",
    "\n",
    "print('Found %d word vectors of glove.' % len(embeddings_index))\n",
    "emb_mean,emb_std = coef.mean(), coef.std()\n",
    "print(emb_mean,emb_std)\n",
    "\n",
    "print('Total %s word vectors.' % len(embeddings_index))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UhP64RZpjzMF"
   },
   "outputs": [],
   "source": [
    "# MAX_NB_WORDS = 28662"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "YwEwM1vFd5dL",
    "outputId": "1ffc8ef0-01d0-4918-aa57-7abbececfde5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing embedding matrix\n",
      "Null word embeddings: 19073\n"
     ]
    }
   ],
   "source": [
    "print('Preparing embedding matrix')\n",
    "nb_words = min(MAX_NB_WORDS, len(word_index))\n",
    "embedding_matrix = np.zeros((nb_words, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    if i >= MAX_NB_WORDS:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "\n",
    "print('Null word embeddings: %d' % np.sum(np.sum(embedding_matrix, axis=1) == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z9NDOZUwd5gT"
   },
   "outputs": [],
   "source": [
    "max_features=100000\n",
    "maxlen=150\n",
    "embed_size=300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vWoKgYo795Nk"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AYOSunB9eADJ"
   },
   "outputs": [],
   "source": [
    "class RocAucEvaluation(Callback):\n",
    "    def __init__(self, validation_data=(), interval=1):\n",
    "        super(Callback, self).__init__()\n",
    "\n",
    "        self.interval = interval\n",
    "        self.X_val, self.y_val = validation_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if epoch % self.interval == 0:\n",
    "            y_pred = self.model.predict(self.X_val, verbose=0)\n",
    "            score = roc_auc_score(self.y_val, y_pred)\n",
    "            print(\"\\n ROC-AUC - epoch: {:d} - score: {:.6f}\".format(epoch+1, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UAvPKg6UlrPJ"
   },
   "outputs": [],
   "source": [
    "from keras.layers import K, Activation\n",
    "from keras.engine import Layer\n",
    "from keras.layers import Dense, Input, Embedding, Dropout, Bidirectional, GRU, Flatten, SpatialDropout1D\n",
    "gru_len = 128\n",
    "Routings = 5\n",
    "Num_capsule = 10\n",
    "Dim_capsule = 16\n",
    "dropout_p = 0.25\n",
    "rate_drop_dense = 0.28\n",
    "\n",
    "def squash(x, axis=-1):\n",
    "    # s_squared_norm is really small\n",
    "    # s_squared_norm = K.sum(K.square(x), axis, keepdims=True) + K.epsilon()\n",
    "    # scale = K.sqrt(s_squared_norm)/ (0.5 + s_squared_norm)\n",
    "    # return scale * x\n",
    "    s_squared_norm = K.sum(K.square(x), axis, keepdims=True)\n",
    "    scale = K.sqrt(s_squared_norm + K.epsilon())\n",
    "    return x / scale\n",
    "\n",
    "\n",
    "# A Capsule Implement with Pure Keras\n",
    "class Capsule(Layer):\n",
    "    def __init__(self, num_capsule, dim_capsule, routings=3, kernel_size=(9, 1), share_weights=True,\n",
    "                 activation='default', **kwargs):\n",
    "        super(Capsule, self).__init__(**kwargs)\n",
    "        self.num_capsule = num_capsule\n",
    "        self.dim_capsule = dim_capsule\n",
    "        self.routings = routings\n",
    "        self.kernel_size = kernel_size\n",
    "        self.share_weights = share_weights\n",
    "        if activation == 'default':\n",
    "            self.activation = squash\n",
    "        else:\n",
    "            self.activation = Activation(activation)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(Capsule, self).build(input_shape)\n",
    "        input_dim_capsule = input_shape[-1]\n",
    "        if self.share_weights:\n",
    "            self.W = self.add_weight(name='capsule_kernel',\n",
    "                                     shape=(1, input_dim_capsule,\n",
    "                                            self.num_capsule * self.dim_capsule),\n",
    "                                     # shape=self.kernel_size,\n",
    "                                     initializer='glorot_uniform',\n",
    "                                     trainable=True)\n",
    "        else:\n",
    "            input_num_capsule = input_shape[-2]\n",
    "            self.W = self.add_weight(name='capsule_kernel',\n",
    "                                     shape=(input_num_capsule,\n",
    "                                            input_dim_capsule,\n",
    "                                            self.num_capsule * self.dim_capsule),\n",
    "                                     initializer='glorot_uniform',\n",
    "                                     trainable=True)\n",
    "\n",
    "    def call(self, u_vecs):\n",
    "        if self.share_weights:\n",
    "            u_hat_vecs = K.conv1d(u_vecs, self.W)\n",
    "        else:\n",
    "            u_hat_vecs = K.local_conv1d(u_vecs, self.W, [1], [1])\n",
    "\n",
    "        batch_size = K.shape(u_vecs)[0]\n",
    "        input_num_capsule = K.shape(u_vecs)[1]\n",
    "        u_hat_vecs = K.reshape(u_hat_vecs, (batch_size, input_num_capsule,\n",
    "                                            self.num_capsule, self.dim_capsule))\n",
    "        u_hat_vecs = K.permute_dimensions(u_hat_vecs, (0, 2, 1, 3))\n",
    "        # final u_hat_vecs.shape = [None, num_capsule, input_num_capsule, dim_capsule]\n",
    "\n",
    "        b = K.zeros_like(u_hat_vecs[:, :, :, 0])  # shape = [None, num_capsule, input_num_capsule]\n",
    "        for i in range(self.routings):\n",
    "            b = K.permute_dimensions(b, (0, 2, 1))  # shape = [None, input_num_capsule, num_capsule]\n",
    "            c = K.softmax(b)\n",
    "            c = K.permute_dimensions(c, (0, 2, 1))\n",
    "            b = K.permute_dimensions(b, (0, 2, 1))\n",
    "            outputs = self.activation(K.batch_dot(c, u_hat_vecs, [2, 2]))\n",
    "            if i < self.routings - 1:\n",
    "                b = K.batch_dot(outputs, u_hat_vecs, [2, 3])\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (None, self.num_capsule, self.dim_capsule)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 343
    },
    "colab_type": "code",
    "id": "6uQACYT2eAJr",
    "outputId": "2c9cfe7b-77b7-4f98-a035-fa75b5ac18d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/34/7d/b1dedde8af99bd82f20ed7e9697aac0597de3049b1f786aa2aac3b9bd4da/Keras-2.2.2-py2.py3-none-any.whl (299kB)\n",
      "\u001b[K    100% |████████████████████████████████| 307kB 14.6MB/s \n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.13)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras) (1.11.0)\n",
      "Collecting keras-preprocessing==1.0.2 (from keras)\n",
      "  Downloading https://files.pythonhosted.org/packages/71/26/1e778ebd737032749824d5cba7dbd3b0cf9234b87ab5ec79f5f0403ca7e9/Keras_Preprocessing-1.0.2-py2.py3-none-any.whl\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (0.19.1)\n",
      "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.8.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.14.5)\n",
      "Collecting keras-applications==1.0.4 (from keras)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/54/90/8f327deaa37a71caddb59b7b4aaa9d4b3e90c0e76f8c2d1572005278ddc5/Keras_Applications-1.0.4-py2.py3-none-any.whl (43kB)\n",
      "\u001b[K    100% |████████████████████████████████| 51kB 16.7MB/s \n",
      "\u001b[?25hInstalling collected packages: keras-preprocessing, keras-applications, keras\n",
      "  Found existing installation: Keras 2.1.6\n",
      "    Uninstalling Keras-2.1.6:\n",
      "      Successfully uninstalled Keras-2.1.6\n",
      "Successfully installed keras-2.2.2 keras-applications-1.0.4 keras-preprocessing-1.0.2\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install --upgrade keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fEIiSJHMeJT8"
   },
   "outputs": [],
   "source": [
    "from keras.layers import concatenate\n",
    "\n",
    "def get_model():\n",
    "    inp1 = Input(shape=(150,))\n",
    "    embed1 = Embedding(max_features, 300, input_length=150, weights=[embedding_matrix], trainable=False)(inp1)\n",
    "    embed1 = SpatialDropout1D(0.4)(embed1)\n",
    "    \n",
    "    x1 = Bidirectional(CuDNNGRU(128, return_sequences=True))(embed1)\n",
    "    capsule1 = Capsule(num_capsule=10, dim_capsule=16, routings=5,share_weights=True)(x1)\n",
    "    # output_capsule1 = Lambda(lambda x: K.sqrt(K.sum(K.square(x), 2)))(capsule1)\n",
    "    capsule1 = GlobalMaxPooling1D()(capsule1)\n",
    "    \n",
    "    inp2 = Input(shape=(150,))\n",
    "    embed2 = Embedding(max_features, 300, input_length=150, weights=[embedding_matrix], trainable=False)(inp2)\n",
    "    embed2 = SpatialDropout1D(0.4)(embed2)\n",
    "    \n",
    "    x2 = Bidirectional(CuDNNGRU(128, return_sequences=True))(embed2)\n",
    "    capsule2 = Capsule(num_capsule=10, dim_capsule=16, routings=5,share_weights=True)(x2)\n",
    "    # output_capsule2 = Lambda(lambda x: K.sqrt(K.sum(K.square(x), 2)))(capsule2)\n",
    "    capsule2 = GlobalMaxPooling1D()(capsule2)\n",
    "    \n",
    "    capsule = concatenate([capsule1, capsule2])\n",
    "    capsule = Dropout(0.2)(capsule)\n",
    "\n",
    "    output = Dense(5, activation='softmax')(capsule)\n",
    "    \n",
    "    model = Model(inputs=[inp1, inp2], outputs=output)\n",
    "    model.compile(\n",
    "        loss='binary_crossentropy',\n",
    "        optimizer=Adam(lr=1e-3,decay=0),\n",
    "        metrics=['accuracy'])\n",
    "#     model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NNFy_sxA97qg"
   },
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "AtoDUsANmRXV",
    "outputId": "b90c8501-4c93-4c60-e328-75b0cfab24c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 606950 samples, validate on 3050 samples\n",
      "Epoch 1/5\n",
      "606950/606950 [==============================] - 663s 1ms/step - loss: 0.2652 - acc: 0.8829 - val_loss: 0.2458 - val_acc: 0.8882\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.24576, saving model to cap_yelp.h5\n",
      "Epoch 2/5\n",
      "606950/606950 [==============================] - 662s 1ms/step - loss: 0.2362 - acc: 0.8935 - val_loss: 0.2390 - val_acc: 0.8893\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.24576 to 0.23904, saving model to cap_yelp.h5\n",
      "Epoch 3/5\n",
      "606950/606950 [==============================] - 662s 1ms/step - loss: 0.2284 - acc: 0.8968 - val_loss: 0.2309 - val_acc: 0.8940\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.23904 to 0.23089, saving model to cap_yelp.h5\n",
      "Epoch 4/5\n",
      "606950/606950 [==============================] - 661s 1ms/step - loss: 0.2234 - acc: 0.8990 - val_loss: 0.2326 - val_acc: 0.8942\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.23089\n",
      "Epoch 5/5\n",
      "606950/606950 [==============================] - 662s 1ms/step - loss: 0.2201 - acc: 0.9006 - val_loss: 0.2286 - val_acc: 0.8954\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.23089 to 0.22859, saving model to cap_yelp.h5\n"
     ]
    }
   ],
   "source": [
    "file_path=\"cap_yelp.h5\"\n",
    "model = get_model()\n",
    "check_point = ModelCheckpoint(file_path, monitor = \"val_loss\", verbose = 1, save_best_only = True, mode = \"min\")\n",
    "early_stop = EarlyStopping(monitor = \"val_loss\", mode = \"min\", patience = 5)\n",
    "hist = model.fit([data, data_post], y, batch_size=256, epochs=5, verbose = 1, validation_split = 0.005, callbacks = [check_point, early_stop])\n",
    "model.load_weights(file_path)\n",
    "best_score = min(hist.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "500BceLJNOZq",
    "outputId": "5b34815a-16ac-4898-df34-82e6cc2697fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 606950 samples, validate on 3050 samples\n",
      "Epoch 1/2\n",
      "606950/606950 [==============================] - 661s 1ms/step - loss: 0.2173 - acc: 0.9019 - val_loss: 0.2282 - val_acc: 0.8956\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.22859 to 0.22818, saving model to cap_yelp.h5\n",
      "Epoch 2/2\n",
      "606950/606950 [==============================] - 662s 1ms/step - loss: 0.2153 - acc: 0.9030 - val_loss: 0.2274 - val_acc: 0.8973\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.22818 to 0.22736, saving model to cap_yelp.h5\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(file_path)\n",
    "hist = model.fit([data, data_post], y, batch_size=256, epochs=2, verbose = 1, validation_split = 0.005, callbacks = [check_point, early_stop])\n",
    "best_score = min(hist.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R6mxEO2zU0RC"
   },
   "outputs": [],
   "source": [
    "model.load_weights('cap_yelp.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zbxu0OAU9_U-"
   },
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lei015usIcA5"
   },
   "outputs": [],
   "source": [
    "del data, data_post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "aDUnKZ1PmmYe",
    "outputId": "ca573d83-41a6-4408-a449-7ea1f1748092"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 12s 295us/step\n"
     ]
    }
   ],
   "source": [
    "test_predicts = model.predict([test_data, test_data_post], batch_size=1024, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "VXVB2uHAIsiv",
    "outputId": "befe28a5-0f25-4f1a-e21f-63bbb54bdf1e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star_1</th>\n",
       "      <th>star_2</th>\n",
       "      <th>star_3</th>\n",
       "      <th>star_4</th>\n",
       "      <th>star_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.026916</td>\n",
       "      <td>0.972625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.002265</td>\n",
       "      <td>0.122109</td>\n",
       "      <td>0.875471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.009687</td>\n",
       "      <td>0.525380</td>\n",
       "      <td>0.464818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.002537</td>\n",
       "      <td>0.997421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.829805</td>\n",
       "      <td>0.140568</td>\n",
       "      <td>0.020915</td>\n",
       "      <td>0.005474</td>\n",
       "      <td>0.003238</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     star_1    star_2    star_3    star_4    star_5\n",
       "0  0.000033  0.000027  0.000399  0.026916  0.972625\n",
       "1  0.000061  0.000093  0.002265  0.122109  0.875471\n",
       "2  0.000015  0.000100  0.009687  0.525380  0.464818\n",
       "3  0.000024  0.000003  0.000015  0.002537  0.997421\n",
       "4  0.829805  0.140568  0.020915  0.005474  0.003238"
      ]
     },
     "execution_count": 44,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = pd.DataFrame(test_predicts)\n",
    "pred.columns = list_classes\n",
    "pred.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HEWsk4Wk-BkZ"
   },
   "source": [
    "### Convert to One Hot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "K6yzoQRj6uKx",
    "outputId": "f1818d3c-9d00-4d37-ce49-89b8da9ea076"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star_1</th>\n",
       "      <th>star_2</th>\n",
       "      <th>star_3</th>\n",
       "      <th>star_4</th>\n",
       "      <th>star_5</th>\n",
       "      <th>stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.026916</td>\n",
       "      <td>0.972625</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.002265</td>\n",
       "      <td>0.122109</td>\n",
       "      <td>0.875471</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.009687</td>\n",
       "      <td>0.525380</td>\n",
       "      <td>0.464818</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.002537</td>\n",
       "      <td>0.997421</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.829805</td>\n",
       "      <td>0.140568</td>\n",
       "      <td>0.020915</td>\n",
       "      <td>0.005474</td>\n",
       "      <td>0.003238</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     star_1    star_2    star_3    star_4    star_5 stars\n",
       "0  0.000033  0.000027  0.000399  0.026916  0.972625     5\n",
       "1  0.000061  0.000093  0.002265  0.122109  0.875471     5\n",
       "2  0.000015  0.000100  0.009687  0.525380  0.464818     4\n",
       "3  0.000024  0.000003  0.000015  0.002537  0.997421     5\n",
       "4  0.829805  0.140568  0.020915  0.005474  0.003238     1"
      ]
     },
     "execution_count": 45,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred['stars'] = pred.idxmax(axis=1)\n",
    "pred['stars'] = pred['stars'].apply(lambda x: re.sub(r\"[^0-9+]\", \"\", x))\n",
    "pred.to_csv('pred_5star_classes.csv', index=False)\n",
    "pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "bAOPya0qKc7W",
    "outputId": "7252b351-76be-41f9-e9ed-5684c0ee9b69"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star_1</th>\n",
       "      <th>star_2</th>\n",
       "      <th>star_3</th>\n",
       "      <th>star_4</th>\n",
       "      <th>star_5</th>\n",
       "      <th>stars</th>\n",
       "      <th>stars_1</th>\n",
       "      <th>stars_2</th>\n",
       "      <th>stars_3</th>\n",
       "      <th>stars_4</th>\n",
       "      <th>stars_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.026916</td>\n",
       "      <td>0.972625</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.002265</td>\n",
       "      <td>0.122109</td>\n",
       "      <td>0.875471</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.009687</td>\n",
       "      <td>0.525380</td>\n",
       "      <td>0.464818</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.002537</td>\n",
       "      <td>0.997421</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.829805</td>\n",
       "      <td>0.140568</td>\n",
       "      <td>0.020915</td>\n",
       "      <td>0.005474</td>\n",
       "      <td>0.003238</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     star_1    star_2    star_3    star_4    star_5 stars  stars_1  stars_2  \\\n",
       "0  0.000033  0.000027  0.000399  0.026916  0.972625     5        0        0   \n",
       "1  0.000061  0.000093  0.002265  0.122109  0.875471     5        0        0   \n",
       "2  0.000015  0.000100  0.009687  0.525380  0.464818     4        0        0   \n",
       "3  0.000024  0.000003  0.000015  0.002537  0.997421     5        0        0   \n",
       "4  0.829805  0.140568  0.020915  0.005474  0.003238     1        1        0   \n",
       "\n",
       "   stars_3  stars_4  stars_5  \n",
       "0        0        0        1  \n",
       "1        0        0        1  \n",
       "2        0        1        0  \n",
       "3        0        0        1  \n",
       "4        0        0        0  "
      ]
     },
     "execution_count": 46,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred['stars'].astype('object', inplace=True)\n",
    "pred = pd.concat([pred, pd.get_dummies(pred['stars'], prefix='stars')], axis=1)\n",
    "pred.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XsVx_Lfx-HNr"
   },
   "source": [
    "## Test Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "B4FRBcf4I6kz",
    "outputId": "796f4c43-014c-4f24-91bb-5886e30efd13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Star : 1 Accuracy : 0.939425\n",
      "Star : 2 Accuracy : 0.920975\n",
      "Star : 3 Accuracy : 0.922675\n",
      "Star : 4 Accuracy : 0.844475\n",
      "Star : 5 Accuracy : 0.87395\n",
      "Mean Accuracy on Test Data:  0.9003\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "acc = 0\n",
    "\n",
    "for i in range(1, 6):\n",
    "    print ('Star : {} Accuracy : {}'.format(i, accuracy_score(test_df['star_{}'.format(i)], pred['stars_{}'.format(i)])))\n",
    "    acc += accuracy_score(test_df['star_{}'.format(i)], pred['stars_{}'.format(i)])\n",
    "\n",
    "acc /= 5\n",
    "print ('Mean Accuracy on Test Data: ', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "tue_ic9XoVrx",
    "outputId": "42fded76-cb90-4ddc-fd72-6c5ebae15ae0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>star_1</th>\n",
       "      <th>star_2</th>\n",
       "      <th>star_3</th>\n",
       "      <th>star_4</th>\n",
       "      <th>star_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>610001</th>\n",
       "      <td>5</td>\n",
       "      <td>karen always checks in with me before the mass...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610002</th>\n",
       "      <td>5</td>\n",
       "      <td>i really enjoyed my time at around the bend bo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610003</th>\n",
       "      <td>4</td>\n",
       "      <td>really tasty thai food we had to wait for 10 -...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610004</th>\n",
       "      <td>5</td>\n",
       "      <td>scott is the best if you are looking for quali...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610005</th>\n",
       "      <td>1</td>\n",
       "      <td>wow ! checking in to our room at 5pm check in ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        stars                                               text  star_1  \\\n",
       "610001      5  karen always checks in with me before the mass...       0   \n",
       "610002      5  i really enjoyed my time at around the bend bo...       0   \n",
       "610003      4  really tasty thai food we had to wait for 10 -...       0   \n",
       "610004      5  scott is the best if you are looking for quali...       0   \n",
       "610005      1  wow ! checking in to our room at 5pm check in ...       1   \n",
       "\n",
       "        star_2  star_3  star_4  star_5  \n",
       "610001       0       0       0       1  \n",
       "610002       0       0       0       1  \n",
       "610003       0       0       1       0  \n",
       "610004       0       0       0       1  \n",
       "610005       0       0       0       0  "
      ]
     },
     "execution_count": 48,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xe5VQrz5eaOM"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "y_6nJR309gkK",
    "L_OfwtVU9lEw",
    "YWtATJd49wsv"
   ],
   "name": "yelpf_cap.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
